{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2177d61d",
   "metadata": {},
   "source": [
    "# VISTA Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fed0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n",
    "\n",
    "def find_image_in_subfolders(image_dir, filename):\n",
    "    pattern = os.path.join(image_dir, \"**\", filename)\n",
    "    path_candidates = glob.glob(pattern, recursive=True)\n",
    "    if path_candidates:\n",
    "        return path_candidates[0]\n",
    "    return None\n",
    "\n",
    "def qwen_test_few_shots(\n",
    "    images_list_of_lists,\n",
    "    prompts,\n",
    "    model_name=\"Qwen/Qwen2-VL-7B-Instruct\",\n",
    "    image_dir=\"path_to_images_directory\",\n",
    "    resize_to=(224, 224),\n",
    "    device_index=0\n",
    "):\n",
    "    device = torch.device(f\"cuda:{device_index}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "        model_name,\n",
    "        torch_dtype=torch.float16\n",
    "    ).eval()\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    processor = AutoProcessor.from_pretrained(model_name)\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    conversation = []\n",
    "    all_processed_images = []\n",
    "\n",
    "    if len(images_list_of_lists) != len(prompts):\n",
    "        raise ValueError(\n",
    "            f\"Mismatched lengths: got {len(images_list_of_lists)} image-turns \"\n",
    "            f\"and {len(prompts)} prompt-turns.\"\n",
    "        )\n",
    "\n",
    "    for img_filenames, prompt_dict in zip(images_list_of_lists, prompts):\n",
    "        role = prompt_dict.get(\"role\", \"user\")  # default to \"user\"\n",
    "        text = prompt_dict.get(\"text\", \"\")\n",
    "\n",
    "        turn_images = []\n",
    "        for fn in img_filenames:\n",
    "            path = find_image_in_subfolders(image_dir, fn)\n",
    "            if path is None:\n",
    "                print(f\"Could not find file '{fn}' in '{image_dir}' or any subfolders.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                raw_image = Image.open(path).convert(\"RGB\")\n",
    "                raw_image = raw_image.resize(resize_to, Image.LANCZOS)\n",
    "                turn_images.append(raw_image)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load image {path} due to error: {e}\")\n",
    "                continue\n",
    "\n",
    "        print(\"Number of images used in this turn:\", len(turn_images))\n",
    "\n",
    "        all_processed_images.extend(turn_images)\n",
    "\n",
    "        turn_content = [{\"type\": \"image\"} for _ in turn_images]\n",
    "        if text:\n",
    "            turn_content.append({\"type\": \"text\", \"text\": text})\n",
    "\n",
    "        conversation.append({\n",
    "            \"role\": role,\n",
    "            \"content\": turn_content\n",
    "        })\n",
    "\n",
    "    if not all_processed_images:\n",
    "        return [], \"No valid images were processed.\"\n",
    "\n",
    "    text_prompt = processor.apply_chat_template(\n",
    "        conversation,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    inputs = processor(\n",
    "        text=[text_prompt],\n",
    "        images=all_processed_images,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        max_length=256\n",
    "    )\n",
    "    inputs = {k: v.to(device, non_blocking=True) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=256,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=False\n",
    "        )\n",
    "\n",
    "    generated_ids = [\n",
    "        output_id[len(input_id):]\n",
    "        for input_id, output_id in zip(inputs['input_ids'], output_ids)\n",
    "    ]\n",
    "\n",
    "    story_description = processor.batch_decode(\n",
    "        generated_ids,\n",
    "        skip_special_tokens=True,\n",
    "        clean_up_tokenization_spaces=True\n",
    "    )[0]\n",
    "\n",
    "    return all_processed_images, story_description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f0671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import uuid\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "aspects = [\n",
    "    \"Structure: Generate the story that intrinsically have the classic five act structure of exposition, rising action, climax, falling action, and resolution. Do not literally include these 5 keywords in the generated story\",\n",
    "    \"Setting: Focus on the location and setting of the image. Enhance how these locations and settings contribute to deeper narrative meanings in the story.\",\n",
    "    \"Clarity: Clarity in writing means expressing ideas in a straightforward, precise, and unambiguous manner. It allows readers to grasp concepts quickly without needing to reread or decode complex structures.\",\n",
    "    \"Cause-and-Effect: Discusses unity of action, emphasising cause-and-effect in storytelling.\",\n",
    "    \"Consistency: Ensure a consistent traits aisnd motivations in the story to maintain the believability of the readers.Ensure that the characters' actions align with their established traits and motivations\",\n",
    "    \"Relatability: Explores emotional drives that relates to the reader. Ensure the audience empathise with or understand the characters' experiences and emotions\",\n",
    "    \"Development: Focus on a specific set of characters in the image and craft well-developed with distinct traits and motivations between them\",\n",
    "    \"Comedy: Introduce a funny twist in the story with the intention of creating a laugh in the reader\"\n",
    "]\n",
    "\n",
    "csv_input_filename = \"combined_unique_id.csv\"\n",
    "\n",
    "story_data = []\n",
    "with open(csv_input_filename, 'r', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        story_id = row[\"story_id\"].strip()\n",
    "        images_list = row[\"image_sequence\"].split(\",\")\n",
    "        images_list = [img.strip() for img in images_list]\n",
    "        story_data.append((story_id, images_list))\n",
    "\n",
    "today_date = datetime.now().strftime('%Y%m%d')\n",
    "folder_name = f\"{today_date}_multi_aspect_generate\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "csv_output_filename = os.path.join(folder_name, f\"{folder_name}.csv\")\n",
    "\n",
    "def build_general_instruction(aspect_text):\n",
    "    \"\"\"\n",
    "    Builds the 'system' prompt instruction for the given aspect.\n",
    "    \"\"\"\n",
    "    return f\"\"\"You are an advanced assistant designed to create a 5-sentence story based on a 5-image sequence input.\n",
    "Your task is to generate the appropriate text for each image input.\n",
    "You are given a 5-sequence image and also an aspect to enhance.\n",
    "This aspect will consist of the aspect name and definition, explaining how to express that particular aspect.\n",
    "Your objective is to generate a 5-sentence story that expresses this aspect while still accurately visualizing the related image.\n",
    "Vary between first-person and third-person viewpoints.\n",
    "You can generate a named entity for the entities detected in the image.\n",
    "\n",
    "Focused aspect: {aspect_text}\n",
    "\n",
    "Generate a story based on the input image\n",
    "\"\"\"\n",
    "\n",
    "def build_evaluator_instruction(aspect_text, generated_story):\n",
    "    \"\"\"\n",
    "    Builds the 'system' prompt instruction for evaluating how well\n",
    "    the generated story expresses the aspect.\n",
    "    \"\"\"\n",
    "    return f\"\"\"You are an advanced assistant tasked to evaluate a generated story.\n",
    "Your task is to evaluate whether the given aspect has been successfully expressed in the story.\n",
    "You will be given an aspect which will consist of the aspect name and definition, explaining how to express that particular aspect.\n",
    "Your output will be one of these 3 options:\n",
    "1) Fully agree, if you think that the story successfully expresses the aspect perfectly\n",
    "2) Partially agree, if you think that the story contains the aspect but has flaws\n",
    "3) Disagree, if you think that the story does not express the related aspect\n",
    "\n",
    "Enhanced Aspect: {aspect_text}\n",
    "\n",
    "Evaluate this story: \\\"{generated_story}\\\"\n",
    "\"\"\"\n",
    "\n",
    "with open(csv_output_filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow([\n",
    "        \"story_id\",\n",
    "        \"aspect\",\n",
    "        \"prompts\",\n",
    "        \"generated_story\",\n",
    "        \"enhanced_prompts\",\n",
    "        \"enhanced_generated_story\"\n",
    "    ])\n",
    "\n",
    "    for story_id, final_story_images in story_data:\n",
    "\n",
    "        for aspect in aspects:\n",
    "\n",
    "            general_instruction = build_general_instruction(aspect)\n",
    "\n",
    "            prompts = []\n",
    "            images_list_of_lists = []\n",
    "\n",
    "            prompts.append({\"role\": \"system\", \"text\": general_instruction})\n",
    "\n",
    "            images_list_of_lists.append(final_story_images)\n",
    "\n",
    "            processed_images, story_response = qwen_test_few_shots(\n",
    "                images_list_of_lists=images_list_of_lists,\n",
    "                prompts=prompts,\n",
    "                image_dir=\"my_images\"\n",
    "            )\n",
    "\n",
    "            print(f\"Generated Story (story_id={story_id}, aspect='{aspect}'):\\n{story_response}\\n\")\n",
    "\n",
    "            formatted_prompts = \"\\n\".join(\n",
    "                f\"{idx+1}) Role: {entry['role'].capitalize()}, Text: {entry['text']}\"\n",
    "                for idx, entry in enumerate(prompts)\n",
    "            )\n",
    "\n",
    "            evaluator_instruction = build_evaluator_instruction(aspect, story_response)\n",
    "            evaluation_prompts = [{\"role\": \"system\", \"text\": evaluator_instruction}]\n",
    "            new_images_list_of_lists = [final_story_images]  # If needed\n",
    "\n",
    "            processed_images_eval, evaluation_response = qwen_test_few_shots(\n",
    "                images_list_of_lists=new_images_list_of_lists,\n",
    "                prompts=evaluation_prompts,\n",
    "                image_dir=\"my_images\"\n",
    "            )\n",
    "\n",
    "            print(f\"Evaluated Story:\\n{evaluation_response}\\n\")\n",
    "\n",
    "            formatted_evaluation_prompts = \"\\n\".join(\n",
    "                f\"{idx+1}) Role: {entry['role'].capitalize()}, Text: {entry['text']}\"\n",
    "                for idx, entry in enumerate(evaluation_prompts)\n",
    "            )\n",
    "\n",
    "            writer.writerow([\n",
    "                story_id,\n",
    "                aspect,\n",
    "                formatted_prompts,\n",
    "                story_response,\n",
    "                formatted_evaluation_prompts,\n",
    "                evaluation_response\n",
    "            ])\n",
    "\n",
    "print(f\"Exported data to CSV: {csv_output_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c086b31",
   "metadata": {},
   "source": [
    "# VISTAScore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a9a43",
   "metadata": {},
   "source": [
    "1) N-gram matching Scorer: measures lexical overlap to capture common word patterns linked to each aspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75439a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from math import exp, log\n",
    "from typing import List, Tuple\n",
    "\n",
    "def _ngrams(tokens: List[str], n: int) -> Counter:\n",
    "    return Counter(tuple(tokens[i:i + n]) for i in range(len(tokens) - n + 1))\n",
    "\n",
    "def _clipped_counts(\n",
    "    ref_ngrams: List[Counter], cand_ngram_counts: Counter\n",
    ") -> Tuple[int, int]:\n",
    "\n",
    "    matched = 0\n",
    "    for ngram, cand_count in cand_ngram_counts.items():\n",
    "        max_ref_count = max(ref.get(ngram, 0) for ref in ref_ngrams)\n",
    "        matched += min(cand_count, max_ref_count)\n",
    "    return matched, sum(cand_ngram_counts.values())\n",
    "\n",
    "def corpus_bleu_like(\n",
    "    train_dataset: List[str],\n",
    "    target_sentence: str,\n",
    "    max_n: int = 4,\n",
    "    smoothing: float = 1e-9,\n",
    ") -> Tuple[List[float], float]:\n",
    "    \n",
    "    ref_tokens = [ref.split() for ref in train_dataset]\n",
    "    cand_tokens = target_sentence.split()\n",
    "    ref_lens = [len(r) for r in ref_tokens]\n",
    "    cand_len = len(cand_tokens)\n",
    "    \n",
    "    refs_by_n = [\n",
    "        [_ngrams(ref, n) for ref in ref_tokens]\n",
    "        for n in range(1, max_n + 1)\n",
    "    ]\n",
    "    \n",
    "    precisions = []\n",
    "    for n in range(1, max_n + 1):\n",
    "        cand_counts = _ngrams(cand_tokens, n)\n",
    "        matched, total = _clipped_counts(refs_by_n[n - 1], cand_counts)\n",
    "        precisions.append((matched + smoothing) / (total + smoothing))\n",
    "    \n",
    "    closest_ref_len = min(ref_lens, key=lambda rl: (abs(rl - cand_len), rl))\n",
    "    if cand_len > closest_ref_len:\n",
    "        bp = 1.0\n",
    "    else:\n",
    "        bp = exp(1 - closest_ref_len / (cand_len + 1e-9))\n",
    "    \n",
    "    log_prec_sum = sum(log(p) for p in precisions) / max_n\n",
    "    bleu = bp * exp(log_prec_sum)\n",
    "    \n",
    "    return precisions, bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beaec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = \"path_to_vista_dataset.csv\"\n",
    "train_df = pd.read_csv(csv_path)\n",
    "\n",
    "cand_path = \"path_to_machine_generated_stories.csv\"\n",
    "cand_df = pd.read_csv(cand_path)\n",
    "\n",
    "refs_by_aspect = ( \n",
    "    train_df\n",
    "    .dropna(subset=[\"generated_story\", \"aspect\"])\n",
    "    .groupby(\"aspect\")[\"generated_story\"]\n",
    "    .apply(lambda col: col.astype(str).tolist())\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "num_aspects   = len(refs_by_aspect)\n",
    "cand_df = cand_df.iloc[:500]                    # limit to first 500 rows\n",
    "num_candidates = len(cand_df)\n",
    "\n",
    "aspect_avg_scores = {}\n",
    "all_records = []\n",
    "\n",
    "for idx, (aspect, refs) in enumerate(refs_by_aspect.items(), 1):\n",
    "    print(f\"[{idx}/{num_aspects}] scoring {num_candidates} stories \"\n",
    "          f\"against aspect: {aspect!r}\")\n",
    "\n",
    "    scores = []\n",
    "    for j, story in enumerate(cand_df[\"generated_story\"].astype(str), 1):\n",
    "        if j % 100 == 0 or j == num_candidates:\n",
    "            print(f\"   …{j}/{num_candidates} done\", end=\"\\r\")\n",
    "\n",
    "        _, bleu = corpus_bleu_like(refs, story)\n",
    "        scores.append(bleu)\n",
    "        all_records.append({\"aspect\": aspect,\n",
    "                            \"generated_story\": story,\n",
    "                            \"bleu_score\": bleu})\n",
    "\n",
    "    aspect_avg_scores[aspect] = mean(scores)\n",
    "    print(f\"   → aspect avg BLEU: {aspect_avg_scores[aspect]:.4f}\")\n",
    "\n",
    "print(\"\\nAverage BLEU-like score per aspect:\")\n",
    "for asp, sc in sorted(aspect_avg_scores.items()):\n",
    "    print(f\"  {asp}: {sc:.4f}\")\n",
    "\n",
    "overall_avg = mean(aspect_avg_scores.values())\n",
    "print(f\"\\nMean of aspect averages: {overall_avg:.4f}\")\n",
    "\n",
    "pd.DataFrame(all_records).to_csv(\"qwen_bleu_scores_all_aspects_vist.csv\", index=False)\n",
    "print(\"\\nDetailed file saved to bleu_scores_all_aspects.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b111a9",
   "metadata": {},
   "source": [
    "2. Sentence-level Semantics Scorer: assesses similarity at the sentence level, accommodating different keywords or phrasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ebcfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "import pandas as pd\n",
    "from bert_score import score\n",
    "\n",
    "CSV_TRAIN   = \"path_to_vista_dataset.csv\"\n",
    "CSV_CAND    = \"path_to_machine_generated_stories.csv\"\n",
    "MODEL_TYPE  = \"microsoft/deberta-large-mnli\"\n",
    "\n",
    "train_df = pd.read_csv(CSV_TRAIN)\n",
    "cand_df  = pd.read_csv(CSV_CAND)\n",
    "\n",
    "refs_by_aspect = (\n",
    "    train_df\n",
    "    .dropna(subset=[\"generated_story\", \"aspect\"])\n",
    "    .groupby(\"aspect\")[\"generated_story\"]\n",
    "    .apply(list)\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "cands = cand_df[\"generated_story\"].astype(str).tolist()[:500]\n",
    "\n",
    "aspect_avg_scores = {}\n",
    "all_records       = []\n",
    "\n",
    "for idx, (aspect, refs) in enumerate(refs_by_aspect.items(), 1):\n",
    "    print(f\"[{idx}/{len(refs_by_aspect)}] scoring {len(cands)} stories \"\n",
    "          f\"against aspect '{aspect}' ({len(refs)} refs)\")\n",
    "\n",
    "    refs_multi = [refs] * len(cands)\n",
    "\n",
    "    _, _, f1 = score(\n",
    "        cands,\n",
    "        refs_multi,\n",
    "        lang=\"en\",\n",
    "        model_type=MODEL_TYPE,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    for story, s in zip(cands, f1.tolist()):\n",
    "        all_records.append({\n",
    "            \"aspect\":          aspect,\n",
    "            \"generated_story\": story,\n",
    "            \"bertscore_f1\":    s\n",
    "        })\n",
    "\n",
    "    aspect_avg_scores[aspect] = f1.mean().item()\n",
    "    print(f\"   → aspect-avg BERTScore-F1: {aspect_avg_scores[aspect]:.4f}\")\n",
    "\n",
    "print(\"\\nAverage BERTScore-F1 per aspect:\")\n",
    "for asp, sc in sorted(aspect_avg_scores.items()):\n",
    "    print(f\"  {asp}: {sc:.4f}\")\n",
    "\n",
    "overall_avg = mean(aspect_avg_scores.values())\n",
    "print(f\"\\nMean of aspect averages: {overall_avg:.4f}\")\n",
    "\n",
    "OUT_CSV = \"bertscore_F1_all_aspects_vista_qwen.csv\"\n",
    "pd.DataFrame(all_records).to_csv(OUT_CSV, index=False)\n",
    "print(f\"\\nDetailed file saved to {OUT_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991438f3",
   "metadata": {},
   "source": [
    "3. Keyword-level Semantics Scorer: measures alignment with dominant aspect-specific keywords that strongly influence narrative structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90927ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "CSV_TRAIN = \"path_to_vista_dataset.csv\"\n",
    "\n",
    "CSV_CAND = \"path_to_machine_generated_stories.csv\"\n",
    "\n",
    "EMBEDDING_MODEL = \"clip-ViT-B-32\"\n",
    "\n",
    "TOP_N = 10  # number of keywords per aspect\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\", \"parser\"])\n",
    "embedder = SentenceTransformer(EMBEDDING_MODEL)\n",
    "\n",
    "df_train = (\n",
    "    pd.read_csv(CSV_TRAIN)\n",
    "      .dropna(subset=[\"generated_story\", \"aspect\"])\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "def preprocess(text: str) -> str:\n",
    "    doc = nlp(text.lower())\n",
    "    return \" \".join(\n",
    "        tok.lemma_ for tok in doc\n",
    "        if tok.pos_ in {\"NOUN\", \"VERB\"} and tok.is_alpha and not tok.is_stop\n",
    "    )\n",
    "\n",
    "print(f\"Loaded {len(df_train)} training stories.\")\n",
    "df_train[\"cleaned\"] = df_train[\"generated_story\"].map(preprocess)\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1, 2), min_df=5, max_df=0.8, stop_words=\"english\"\n",
    ")\n",
    "X = vectorizer.fit_transform(df_train[\"cleaned\"])\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "print(\"Computed TF–IDF matrix.\")\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X, df_train[\"aspect\"])\n",
    "classes = clf.classes_\n",
    "coefs = clf.coef_\n",
    "\n",
    "distinctive_terms = {}\n",
    "for i, aspect in enumerate(classes):\n",
    "    idxs = np.argsort(coefs[i])[-TOP_N:]\n",
    "    distinctive_terms[aspect] = terms[idxs].tolist()\n",
    "print(f\"Extracted top {TOP_N} distinctive keywords for {len(distinctive_terms)} aspects.\")\n",
    "\n",
    "aspect_embeddings = {}\n",
    "print(\"Embedding distinctive keywords for each aspect...\")\n",
    "for i, (aspect, kws) in enumerate(distinctive_terms.items(), start=1):\n",
    "    first_word = aspect.split()[0]\n",
    "    print(f\"[{i}/{len(distinctive_terms)}] Aspect '{first_word}' => {', '.join(kws)}\")\n",
    "    emb = embedder.encode(kws)\n",
    "    aspect_embeddings[aspect] = np.mean(emb, axis=0)\n",
    "\n",
    "df_cand = pd.read_csv(CSV_CAND).dropna(subset=[\"generated_story\"]).reset_index(drop=True)\n",
    "print(f\"Loaded {len(df_cand)} candidate stories to evaluate.\")\n",
    "df_cand[\"cleaned\"] = df_cand[\"generated_story\"].map(preprocess)\n",
    "\n",
    "stories = df_cand[\"cleaned\"].tolist()\n",
    "print(\"Embedding candidate stories...\")\n",
    "story_embs = embedder.encode(stories, show_progress_bar=True)\n",
    "\n",
    "mean_distances = {}\n",
    "print(\"Computing mean distances per aspect...\")\n",
    "for aspect, a_emb in aspect_embeddings.items():\n",
    "    first_word = aspect.split()[0]\n",
    "    dists = cosine_distances([a_emb], story_embs)[0]\n",
    "    mean_distances[aspect] = np.mean(dists)\n",
    "    print(f\"Aspect '{first_word}': mean distance = {mean_distances[aspect]:.4f}\")\n",
    "\n",
    "print(\"\\nDistinctive keywords per aspect:\")\n",
    "for aspect, kws in distinctive_terms.items():\n",
    "    first_word = aspect.split()[0]\n",
    "    print(f\"{first_word}: {', '.join(kws)}\")\n",
    "\n",
    "print(\"\\nFinal mean cosine distances to candidate stories per aspect:\")\n",
    "for aspect, dist in sorted(mean_distances.items(), key=lambda x: x[1]):\n",
    "    first_word = aspect.split()[0]\n",
    "    print(f\"{first_word}: {dist:.4f}\")\n",
    "\n",
    "overall_mean = np.mean(list(mean_distances.values()))\n",
    "print(f\"\\nOverall mean distance across all aspects: {overall_mean:.4f}\")\n",
    "\n",
    "pd.DataFrame(\n",
    "    [(aspect.split()[0], dist) for aspect, dist in mean_distances.items()],\n",
    "    columns=[\"aspect\", \"mean_distance\"]\n",
    ").to_csv(\"aspect_mean_distances.csv\", index=False)\n",
    "print(\"Saved mean distances to aspect_mean_distances.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5224d14b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vist",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
